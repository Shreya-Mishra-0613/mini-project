{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d80fac0-5b25-4b03-bd42-423260dc2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608f753d-cf6d-4547-80cf-51a4c80f3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5745ebfb-7985-4177-8cf2-b0087f967c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\SHREYA\n",
      "[nltk_data]     MISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\SHREYA\n",
      "[nltk_data]     MISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\SHREYA\n",
      "[nltk_data]     MISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df698c7c-b4bd-48b2-adbc-f90986559c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61d9c31-c751-44bf-b299-4a8dcd42921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/local_ocean_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a7eb9e-f60d-4405-adca-a1bd241b7895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1160, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16203008-1432-42ca-8a18-3dbccafea58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Impeccability is the source of wonder.</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>I'm impressed by the author's research and ana...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Those who dare, author history.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Philosophy: Iâ€™m not weird, Iâ€™m a limited editi...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>This blog post is a goldmine of information.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Adulthood is just saying 'But after this week,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>â€˜Just one more episodeâ€™ - famous last words. ðŸ“ºâŒ›</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>This post has inspired me to take action.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>I'm enchanted by the taste of this gourmet cho...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>I'm grateful for the insights shared in this a...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Openness  \\\n",
       "381              Impeccability is the source of wonder.       5.1   \n",
       "911   I'm impressed by the author's research and ana...       4.3   \n",
       "281                     Those who dare, author history.       3.8   \n",
       "572   Philosophy: Iâ€™m not weird, Iâ€™m a limited editi...       5.3   \n",
       "861        This blog post is a goldmine of information.       4.3   \n",
       "683   Adulthood is just saying 'But after this week,...       4.0   \n",
       "420     â€˜Just one more episodeâ€™ - famous last words. ðŸ“ºâŒ›       4.1   \n",
       "925           This post has inspired me to take action.       4.1   \n",
       "1089  I'm enchanted by the taste of this gourmet cho...       4.5   \n",
       "976   I'm grateful for the insights shared in this a...       4.1   \n",
       "\n",
       "      Conscientiousness  Extraversion  Agreeableness  Neuroticism  \n",
       "381                 3.2           4.1            4.7          0.4  \n",
       "911                 4.0           3.9            4.1          3.3  \n",
       "281                 4.3           5.0            3.0          0.1  \n",
       "572                 1.6           3.7            5.1          1.1  \n",
       "861                 3.7           4.0            4.1          3.3  \n",
       "683                 2.3           3.8            2.7          4.0  \n",
       "420                 1.5           4.4            3.4          3.7  \n",
       "925                 4.3           3.6            4.2          3.1  \n",
       "1089                3.9           3.7            4.2          2.8  \n",
       "976                 4.2           3.8            4.4          3.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e337d3-96ea-4cb1-8b51-3a2f48602527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1160 entries, 0 to 1159\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Text               1160 non-null   object \n",
      " 1   Openness           1160 non-null   float64\n",
      " 2   Conscientiousness  1160 non-null   float64\n",
      " 3   Extraversion       1160 non-null   float64\n",
      " 4   Agreeableness      1159 non-null   float64\n",
      " 5   Neuroticism        1159 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 54.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcce8bab-088d-4245-a3ad-a80601d25449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1160.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.962672</td>\n",
       "      <td>3.341724</td>\n",
       "      <td>3.486897</td>\n",
       "      <td>3.700173</td>\n",
       "      <td>2.815272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.758600</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>0.990037</td>\n",
       "      <td>0.802662</td>\n",
       "      <td>1.219452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>6.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Openness  Conscientiousness  Extraversion  Agreeableness  \\\n",
       "count  1160.000000        1160.000000   1160.000000    1159.000000   \n",
       "mean      3.962672           3.341724      3.486897       3.700173   \n",
       "std       0.758600           0.993143      0.990037       0.802662   \n",
       "min       1.300000           0.700000     -1.000000       1.000000   \n",
       "25%       3.600000           2.600000      3.200000       3.200000   \n",
       "50%       4.100000           3.500000      3.700000       3.900000   \n",
       "75%       4.500000           4.100000      4.000000       4.300000   \n",
       "max       5.700000           5.400000      5.300000       5.300000   \n",
       "\n",
       "       Neuroticism  \n",
       "count  1159.000000  \n",
       "mean      2.815272  \n",
       "std       1.219452  \n",
       "min      -1.200000  \n",
       "25%       2.200000  \n",
       "50%       2.900000  \n",
       "75%       3.500000  \n",
       "max       6.700000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0f278-1f6e-4739-8511-3ce795c3477d",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d576d3d8-2508-46e4-a6ff-e373550a9058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text                 0\n",
       "Openness             0\n",
       "Conscientiousness    0\n",
       "Extraversion         0\n",
       "Agreeableness        1\n",
       "Neuroticism          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495e751c-d24d-44d5-999d-7f09315f3555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a3c9ea-e6f3-4af5-ab9d-74de86b7b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1159 entries, 0 to 1158\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Text               1159 non-null   object \n",
      " 1   Openness           1159 non-null   float64\n",
      " 2   Conscientiousness  1159 non-null   float64\n",
      " 3   Extraversion       1159 non-null   float64\n",
      " 4   Agreeableness      1159 non-null   float64\n",
      " 5   Neuroticism        1159 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 63.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ace378-0534-4d69-a232-7e21455ce663",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2889638a-85d0-4bc0-99fe-0945b786d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5004ecc1-f67b-42d4-ba69-059ed3acf8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03a1032-aefb-4a80-b8de-40d1bd5546c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Low battery is the adult version of needing to...</td>\n",
       "      <td>low battery adult version needing pee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Creative hobbies keep the mind sharp.</td>\n",
       "      <td>creative hobbies keep mind sharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Fearless minds shape the unknown.</td>\n",
       "      <td>fearless minds shape unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>I can't get enough of this artisanal ice cream...</td>\n",
       "      <td>cant get enough artisanal ice cream flavors un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>This tablet has become an essential tool for p...</td>\n",
       "      <td>tablet become essential tool productivity simp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "702   Low battery is the adult version of needing to...   \n",
       "126               Creative hobbies keep the mind sharp.   \n",
       "365                   Fearless minds shape the unknown.   \n",
       "1007  I can't get enough of this artisanal ice cream...   \n",
       "1026  This tablet has become an essential tool for p...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "702               low battery adult version needing pee  \n",
       "126                    creative hobbies keep mind sharp  \n",
       "365                        fearless minds shape unknown  \n",
       "1007  cant get enough artisanal ice cream flavors un...  \n",
       "1026  tablet become essential tool productivity simp...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Text', 'cleaned_text']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1fed7-659d-4718-803c-a42be9731c2f",
   "metadata": {},
   "source": [
    "# Tokenization and Lemmatization\n",
    "## Tokenization\n",
    "- Tokenization is the process of splitting the text into individual words or tokens.\n",
    "\n",
    "## Lemmatization\n",
    "- Lemmatization reduces words to their base or root form. For example, \"running\" becomes \"run,\" and \"better\" becomes \"good.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54fbf345-c1d3-40be-a2ad-fa5691a610c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocess_text.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for tokenization and lemmatization\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "joblib.dump(preprocess_text, 'preprocess_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77d73add-19ea-43f2-b527-035a86ed9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7feca58-06b6-44f9-896f-8967dd21a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love exploring new cultures through cuisine ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>love exploring new cultures cuisine travel</td>\n",
       "      <td>[love, exploring, new, culture, cuisine, travel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My workspace is always organized; I can't focu...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>workspace always organized cant focus messy en...</td>\n",
       "      <td>[workspace, always, organized, ca, focus, mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large social gatherings make me feel energized...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>large social gatherings make feel energized ex...</td>\n",
       "      <td>[large, social, gathering, make, feel, energiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I often worry about things not going as planned.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>often worry things going planned</td>\n",
       "      <td>[often, worry, thing, going, planned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Having a daily routine is comforting and helps...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>daily routine comforting helps productive</td>\n",
       "      <td>[daily, routine, comforting, help, productive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Openness  \\\n",
       "0  I love exploring new cultures through cuisine ...       4.7   \n",
       "1  My workspace is always organized; I can't focu...       2.9   \n",
       "2  Large social gatherings make me feel energized...       3.1   \n",
       "3   I often worry about things not going as planned.       3.0   \n",
       "4  Having a daily routine is comforting and helps...       2.3   \n",
       "\n",
       "   Conscientiousness  Extraversion  Agreeableness  Neuroticism  \\\n",
       "0                3.1           3.5            3.9          2.1   \n",
       "1                4.8           2.1            3.2          2.4   \n",
       "2                2.9           4.6            3.5          1.7   \n",
       "3                3.9           2.0            3.4          4.5   \n",
       "4                4.6           1.7            3.7          2.2   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0         love exploring new cultures cuisine travel   \n",
       "1  workspace always organized cant focus messy en...   \n",
       "2  large social gatherings make feel energized ex...   \n",
       "3                   often worry things going planned   \n",
       "4          daily routine comforting helps productive   \n",
       "\n",
       "                                              tokens  \n",
       "0   [love, exploring, new, culture, cuisine, travel]  \n",
       "1  [workspace, always, organized, ca, focus, mess...  \n",
       "2  [large, social, gathering, make, feel, energiz...  \n",
       "3              [often, worry, thing, going, planned]  \n",
       "4     [daily, routine, comforting, help, productive]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068a842-8bbd-440f-8145-b4ec3c7b9be4",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "- Normalising the data between range 0-1 using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d639be3-b46d-4474-9221-1f64f8ed9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948cb172-9a2f-4dc1-8a56-3fe62ebe7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']] = scaler.fit_transform(\n",
    "    df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb920c7-dbc4-4756-ba76-f3f73e727e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1159.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>1159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.605087</td>\n",
       "      <td>0.561985</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.627947</td>\n",
       "      <td>0.508262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.172469</td>\n",
       "      <td>0.211379</td>\n",
       "      <td>0.157213</td>\n",
       "      <td>0.186666</td>\n",
       "      <td>0.154361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.430380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.518987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Openness  Conscientiousness  Extraversion  Agreeableness  \\\n",
       "count  1159.000000        1159.000000   1159.000000    1159.000000   \n",
       "mean      0.605087           0.561985      0.712177       0.627947   \n",
       "std       0.172469           0.211379      0.157213       0.186666   \n",
       "min       0.000000           0.000000      0.000000       0.000000   \n",
       "25%       0.522727           0.404255      0.666667       0.511628   \n",
       "50%       0.636364           0.595745      0.746032       0.674419   \n",
       "75%       0.727273           0.723404      0.793651       0.767442   \n",
       "max       1.000000           1.000000      1.000000       1.000000   \n",
       "\n",
       "       Neuroticism  \n",
       "count  1159.000000  \n",
       "mean      0.508262  \n",
       "std       0.154361  \n",
       "min       0.000000  \n",
       "25%       0.430380  \n",
       "50%       0.518987  \n",
       "75%       0.594937  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226cad7-8c5d-4400-82c1-244f3b6278ab",
   "metadata": {},
   "source": [
    "### All the values are now between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f276f7-fc8c-45e0-b1d8-bc724fb8abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving normalised data\n",
    "df.to_csv(\"data/standard_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758017ad-58b3-42ec-aebe-7c6f7965d648",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e2a26d1-fad6-443f-bc05-8ddf8e200363",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=650)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fed6f2c-14cd-4f70-aacf-608a84c9925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the 'tokens' column\n",
    "# Join the tokenized words back into a single string for each document\n",
    "tfidf_features = tfidf.fit_transform(df['tokens'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for easier manipulation\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Concatenate the TF-IDF DataFrame with the original DataFrame\n",
    "df = pd.concat([df.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11019033-e69e-4836-a69c-cfb8c1d77d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>wonder</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>worrying</th>\n",
       "      <th>would</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yoga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love exploring new cultures through cuisine ...</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>love exploring new cultures cuisine travel</td>\n",
       "      <td>[love, exploring, new, culture, cuisine, travel]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My workspace is always organized; I can't focu...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>workspace always organized cant focus messy en...</td>\n",
       "      <td>[workspace, always, organized, ca, focus, mess...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large social gatherings make me feel energized...</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>large social gatherings make feel energized ex...</td>\n",
       "      <td>[large, social, gathering, make, feel, energiz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I often worry about things not going as planned.</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>often worry things going planned</td>\n",
       "      <td>[often, worry, thing, going, planned]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Having a daily routine is comforting and helps...</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>daily routine comforting helps productive</td>\n",
       "      <td>[daily, routine, comforting, help, productive]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Openness  \\\n",
       "0  I love exploring new cultures through cuisine ...  0.772727   \n",
       "1  My workspace is always organized; I can't focu...  0.363636   \n",
       "2  Large social gatherings make me feel energized...  0.409091   \n",
       "3   I often worry about things not going as planned.  0.386364   \n",
       "4  Having a daily routine is comforting and helps...  0.227273   \n",
       "\n",
       "   Conscientiousness  Extraversion  Agreeableness  Neuroticism  \\\n",
       "0           0.510638      0.714286       0.674419     0.417722   \n",
       "1           0.872340      0.492063       0.511628     0.455696   \n",
       "2           0.468085      0.888889       0.581395     0.367089   \n",
       "3           0.680851      0.476190       0.558140     0.721519   \n",
       "4           0.829787      0.428571       0.627907     0.430380   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0         love exploring new cultures cuisine travel   \n",
       "1  workspace always organized cant focus messy en...   \n",
       "2  large social gatherings make feel energized ex...   \n",
       "3                   often worry things going planned   \n",
       "4          daily routine comforting helps productive   \n",
       "\n",
       "                                              tokens  absolutely  action  ...  \\\n",
       "0   [love, exploring, new, culture, cuisine, travel]         0.0     0.0  ...   \n",
       "1  [workspace, always, organized, ca, focus, mess...         0.0     0.0  ...   \n",
       "2  [large, social, gathering, make, feel, energiz...         0.0     0.0  ...   \n",
       "3              [often, worry, thing, going, planned]         0.0     0.0  ...   \n",
       "4     [daily, routine, comforting, help, productive]         0.0     0.0  ...   \n",
       "\n",
       "   wonder  word  work  world     worry  worrying  would  wrong  year  yoga  \n",
       "0     0.0   0.0   0.0    0.0  0.000000       0.0    0.0    0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0    0.0  0.000000       0.0    0.0    0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0    0.0  0.000000       0.0    0.0    0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0    0.0  0.535677       0.0    0.0    0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0    0.0  0.000000       0.0    0.0    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 658 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e36de8a-ebbb-4a15-96dc-2cc1b38a51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the vectorizer to a pickle file\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3ab25-c095-426b-84ed-0824d630c4ec",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4a4a92-3e71-4e3e-b0f7-d68dce031982",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Text', 'cleaned_text', 'tokens', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism'])\n",
    "y = df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d31ef82-4a23-4248-a81e-6fedfdf0b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c27b6f22-f4fd-4b2a-9e1d-6299125ec02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (927, 650) (927, 5)\n",
      "Test set: (232, 650) (232, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c058ceb4-e124-4c03-8cfd-2a73c9e08f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "\n",
    "# Save testing data\n",
    "X_test.to_csv('data/X_test.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)\n",
    "\n",
    "df.to_csv('data/model_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
